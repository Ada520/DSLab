{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">EE 379K: Data Science Lab</p>\n",
    "# <p style=\"text-align: center;\">Lab 3 - 9/25/17</p>\n",
    "## <p style=\"text-align: center;\">Rachel Chen and Kevin Yee</p>\n",
    "### <p style=\"text-align: center;\"> rjc2737 and kjy252</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.markdownnotes.com/image_KBazLVB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.markdownnotes.com/image_yVAcZ2O.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cStringIO import StringIO\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import os\n",
    "import sys, getopt\n",
    "\n",
    "#converts pdf, returns its text content as a string\n",
    "def convert(faname, pages=None):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "\n",
    "    output = StringIO()\n",
    "    manager = PDFResourceManager()\n",
    "    converter = TextConverter(manager, output, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(manager, converter)\n",
    "    infile = open(faname, 'rb')\n",
    "    for page in PDFPage.get_pages(infile, pagenums):\n",
    "        interpreter.process_page(page)\n",
    "    infile.close()\n",
    "    converter.close()\n",
    "    text = output.getvalue()\n",
    "    output.close\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib import urlopen\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# path = \"C:\\Users\\Kevin\\Google Drive\\Ipython\\Data Science Lab\\Lab3\\scrapedPDF\\\\\"\n",
    "url = \"http://proceedings.mlr.press/v70/\"\n",
    "content = urllib.urlopen(url).read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://proceedings.mlr.press/v70/achab17a/achab17a.pdf\n"
     ]
    }
   ],
   "source": [
    "soup=BeautifulSoup(content,\"html.parser\")\n",
    "html = soup.find_all(href=re.compile(\"http://.*17[a-z].pdf\"))\n",
    "\n",
    "#more sanity check \n",
    "print html[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(374,len(html)):\n",
    "    pdf_url = html[i]['href']\n",
    "    f = open(path + str(i)+\".pdf\", 'wb')\n",
    "    pdf = urlopen(pdf_url)\n",
    "    f.write(pdf.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converts all pdfs in directory pdfDir, saves all resulting txt files to txtdir\n",
    "def convertMultiple(pdfDir, txtDir):\n",
    "    if pdfDir == \"\": pdfDir = os.getcwd() + \"\\\\\" #if no pdfDir passed in \n",
    "    for pdf in os.listdir(pdfDir): #iterate through pdfs in pdf directory\n",
    "        fileExtension = pdf.split(\".\")[-1]\n",
    "        \n",
    "        pdfFilename = pdfDir + pdf \n",
    "        text = convert(pdfFilename) #get string of text content of pdf\n",
    "        textFilename = txtDir + pdf + \".txt\"\n",
    "        textFile = open(textFilename, \"w\") #make text file\n",
    "        textFile.write(text) #write text to text file\n",
    "\n",
    "pdfDire = \"C:/Users/kevjy/Documents/Fall2017/EE379K/Labs/DSLab/Lab3/scrapedPDF/\"\n",
    "txtDir = \"C:/Users/kevjy/Documents/Fall2017/EE379K/Labs/DSLab/Lab3/scrapedTXT/\"\n",
    "convertMultiple(pdfDire, txtDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.markdownnotes.com/image_TWj4ap5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 135079)\n",
      "('of', 75084)\n",
      "('and', 65208)\n",
      "('to', 47216)\n",
      "('a', 44558)\n",
      "('is', 39589)\n",
      "('in', 37988)\n",
      "('for', 31734)\n",
      "('that', 23932)\n",
      "('we', 22222)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "c, directory = Counter(), \"C:/Users/kevjy/Documents/Fall2017/EE379K/Labs/DSLab/Lab3/scrapedTXT/\"\n",
    "\n",
    "\n",
    "for x in os.listdir(directory):\n",
    "    fname = os.path.join(directory, x)\n",
    "    if os.path.isfile(fname):\n",
    "        with open(fname) as f:\n",
    "            wordList = f.read().split()\n",
    "            englishList = []\n",
    "            for word in wordList:\n",
    "                if word.isalpha():\n",
    "                    englishList.append(word)\n",
    "            c += Counter(englishList)\n",
    "\n",
    "for word, _ in c.most_common(10):\n",
    "    print(word, c[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out a linear model:\n",
    "Following a guide from https://www.kaggle.com/apapiu/regularized-linear-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py:913: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
