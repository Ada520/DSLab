{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG-CV: 0.123236765829\n",
      "ET-CV: 0.145292593988\n",
      "RF-CV: 0.142165116712\n",
      "RD-CV: 0.13183915747\n",
      "LS-CV: 0.143216331902\n",
      "(1460L, 5L),(1459L, 5L)\n",
      "[0]\ttrain-rmse:11.4159+0.00727902\ttest-rmse:11.4159+0.0221769\n",
      "[10]\ttrain-rmse:10.3275+0.00647517\ttest-rmse:10.3275+0.0230641\n",
      "[20]\ttrain-rmse:9.3429+0.00554988\ttest-rmse:9.34287+0.024078\n",
      "[30]\ttrain-rmse:8.45265+0.00513113\ttest-rmse:8.45262+0.0246051\n",
      "[40]\ttrain-rmse:7.64737+0.00467193\ttest-rmse:7.6474+0.0250131\n",
      "[50]\ttrain-rmse:6.91896+0.00423594\ttest-rmse:6.91914+0.024779\n",
      "[60]\ttrain-rmse:6.25991+0.00382696\ttest-rmse:6.26029+0.0242191\n",
      "[70]\ttrain-rmse:5.66403+0.00333421\ttest-rmse:5.66451+0.0240386\n",
      "[80]\ttrain-rmse:5.12525+0.00310455\ttest-rmse:5.12556+0.0236071\n",
      "[90]\ttrain-rmse:4.63784+0.00261148\ttest-rmse:4.63819+0.0235351\n",
      "[100]\ttrain-rmse:4.1968+0.00222746\ttest-rmse:4.19728+0.0232484\n",
      "[110]\ttrain-rmse:3.79794+0.00205526\ttest-rmse:3.79848+0.0227223\n",
      "[120]\ttrain-rmse:3.43715+0.00183187\ttest-rmse:3.43794+0.0225482\n",
      "[130]\ttrain-rmse:3.11085+0.00183727\ttest-rmse:3.11167+0.0220073\n",
      "[140]\ttrain-rmse:2.81547+0.00165127\ttest-rmse:2.81648+0.0215025\n",
      "[150]\ttrain-rmse:2.54862+0.00150657\ttest-rmse:2.54954+0.0212349\n",
      "[160]\ttrain-rmse:2.30705+0.00130642\ttest-rmse:2.30814+0.0208101\n",
      "[170]\ttrain-rmse:2.08882+0.00116716\ttest-rmse:2.08992+0.0206417\n",
      "[180]\ttrain-rmse:1.89149+0.00104317\ttest-rmse:1.89254+0.0204961\n",
      "[190]\ttrain-rmse:1.71301+0.000974087\ttest-rmse:1.71409+0.0202098\n",
      "[200]\ttrain-rmse:1.55154+0.000973555\ttest-rmse:1.55271+0.0195697\n",
      "[210]\ttrain-rmse:1.40567+0.000940617\ttest-rmse:1.40684+0.0192427\n",
      "[220]\ttrain-rmse:1.27376+0.000888538\ttest-rmse:1.27507+0.0186475\n",
      "[230]\ttrain-rmse:1.15473+0.000745746\ttest-rmse:1.15605+0.0185436\n",
      "[240]\ttrain-rmse:1.04711+0.000763499\ttest-rmse:1.04842+0.0184117\n",
      "[250]\ttrain-rmse:0.94991+0.000774051\ttest-rmse:0.951288+0.0180527\n",
      "[260]\ttrain-rmse:0.862076+0.00088868\ttest-rmse:0.863547+0.0176316\n",
      "[270]\ttrain-rmse:0.782661+0.000905749\ttest-rmse:0.784285+0.017355\n",
      "[280]\ttrain-rmse:0.711165+0.000956038\ttest-rmse:0.712832+0.0172403\n",
      "[290]\ttrain-rmse:0.646668+0.000931323\ttest-rmse:0.648612+0.0170974\n",
      "[300]\ttrain-rmse:0.588467+0.000953915\ttest-rmse:0.590472+0.0171222\n",
      "[310]\ttrain-rmse:0.536099+0.00109214\ttest-rmse:0.538243+0.016932\n",
      "[320]\ttrain-rmse:0.488925+0.00119084\ttest-rmse:0.491128+0.016818\n",
      "[330]\ttrain-rmse:0.446454+0.00118174\ttest-rmse:0.448722+0.016761\n",
      "[340]\ttrain-rmse:0.408365+0.00127262\ttest-rmse:0.410835+0.0167324\n",
      "[350]\ttrain-rmse:0.374175+0.00133649\ttest-rmse:0.376924+0.0166961\n",
      "[360]\ttrain-rmse:0.343571+0.0014569\ttest-rmse:0.346565+0.0167196\n",
      "[370]\ttrain-rmse:0.316192+0.0014934\ttest-rmse:0.31952+0.0168206\n",
      "[380]\ttrain-rmse:0.291715+0.00158791\ttest-rmse:0.295322+0.016684\n",
      "[390]\ttrain-rmse:0.269913+0.00172845\ttest-rmse:0.273861+0.0166086\n",
      "[400]\ttrain-rmse:0.250534+0.00192809\ttest-rmse:0.25479+0.0165013\n",
      "[410]\ttrain-rmse:0.233278+0.00197015\ttest-rmse:0.237987+0.0164666\n",
      "[420]\ttrain-rmse:0.218062+0.00201505\ttest-rmse:0.223082+0.0164783\n",
      "[430]\ttrain-rmse:0.204611+0.00213679\ttest-rmse:0.210018+0.0162507\n",
      "[440]\ttrain-rmse:0.192869+0.00218252\ttest-rmse:0.198576+0.0161942\n",
      "[450]\ttrain-rmse:0.182454+0.00225181\ttest-rmse:0.188465+0.0161763\n",
      "[460]\ttrain-rmse:0.17339+0.00229882\ttest-rmse:0.179685+0.0162\n",
      "[470]\ttrain-rmse:0.165491+0.00245499\ttest-rmse:0.172184+0.0160998\n",
      "[480]\ttrain-rmse:0.158594+0.00257442\ttest-rmse:0.1656+0.0159823\n",
      "[490]\ttrain-rmse:0.152608+0.0026609\ttest-rmse:0.15999+0.0158252\n",
      "[500]\ttrain-rmse:0.147384+0.00278144\ttest-rmse:0.155117+0.0156717\n",
      "[510]\ttrain-rmse:0.142866+0.00284545\ttest-rmse:0.150896+0.015534\n",
      "[520]\ttrain-rmse:0.138862+0.00294952\ttest-rmse:0.147293+0.0153674\n",
      "[530]\ttrain-rmse:0.135442+0.00296342\ttest-rmse:0.144211+0.0151999\n",
      "[540]\ttrain-rmse:0.132498+0.00297317\ttest-rmse:0.141589+0.0150379\n",
      "[550]\ttrain-rmse:0.129944+0.00301671\ttest-rmse:0.139258+0.0149735\n",
      "[560]\ttrain-rmse:0.127705+0.003078\ttest-rmse:0.137292+0.0147586\n",
      "[570]\ttrain-rmse:0.125758+0.00312417\ttest-rmse:0.135502+0.0145954\n",
      "[580]\ttrain-rmse:0.124052+0.00317401\ttest-rmse:0.134051+0.0143728\n",
      "[590]\ttrain-rmse:0.12254+0.00322\ttest-rmse:0.132852+0.0142219\n",
      "[600]\ttrain-rmse:0.121228+0.00325943\ttest-rmse:0.131756+0.0139814\n",
      "[610]\ttrain-rmse:0.120049+0.00327639\ttest-rmse:0.130835+0.0137233\n",
      "[620]\ttrain-rmse:0.119022+0.00322133\ttest-rmse:0.130045+0.0135725\n",
      "[630]\ttrain-rmse:0.118119+0.00322283\ttest-rmse:0.129338+0.0134145\n",
      "[640]\ttrain-rmse:0.117298+0.00324926\ttest-rmse:0.128724+0.013308\n",
      "[650]\ttrain-rmse:0.116538+0.00324445\ttest-rmse:0.128204+0.0132238\n",
      "[660]\ttrain-rmse:0.115849+0.00323107\ttest-rmse:0.127728+0.0131176\n",
      "[670]\ttrain-rmse:0.115247+0.00322321\ttest-rmse:0.12738+0.013022\n",
      "[680]\ttrain-rmse:0.11466+0.00320812\ttest-rmse:0.126947+0.0128993\n",
      "[690]\ttrain-rmse:0.114171+0.00323328\ttest-rmse:0.126572+0.012754\n",
      "[700]\ttrain-rmse:0.113702+0.00322367\ttest-rmse:0.126375+0.0127318\n",
      "[710]\ttrain-rmse:0.113278+0.00322386\ttest-rmse:0.126194+0.0126259\n",
      "[720]\ttrain-rmse:0.11286+0.00320386\ttest-rmse:0.125853+0.0125247\n",
      "[730]\ttrain-rmse:0.11247+0.00318277\ttest-rmse:0.125639+0.0124276\n",
      "[740]\ttrain-rmse:0.112083+0.0031594\ttest-rmse:0.125436+0.0123699\n",
      "[750]\ttrain-rmse:0.111743+0.00313588\ttest-rmse:0.125216+0.0123336\n",
      "[760]\ttrain-rmse:0.111421+0.0031222\ttest-rmse:0.125003+0.0122534\n",
      "[770]\ttrain-rmse:0.111102+0.00311079\ttest-rmse:0.1249+0.0122925\n",
      "[780]\ttrain-rmse:0.11082+0.00311033\ttest-rmse:0.124758+0.0122068\n",
      "[790]\ttrain-rmse:0.110544+0.0030879\ttest-rmse:0.124605+0.0121989\n",
      "[800]\ttrain-rmse:0.110254+0.00307255\ttest-rmse:0.124483+0.0122098\n",
      "[810]\ttrain-rmse:0.109991+0.00304008\ttest-rmse:0.124372+0.0121878\n",
      "[820]\ttrain-rmse:0.109755+0.00303853\ttest-rmse:0.124277+0.0121222\n",
      "[830]\ttrain-rmse:0.109541+0.00302794\ttest-rmse:0.124211+0.0120804\n",
      "[840]\ttrain-rmse:0.109314+0.00301775\ttest-rmse:0.124149+0.0120605\n",
      "[850]\ttrain-rmse:0.109097+0.00300089\ttest-rmse:0.124053+0.0120207\n",
      "[860]\ttrain-rmse:0.108868+0.00299545\ttest-rmse:0.123988+0.0119742\n",
      "[870]\ttrain-rmse:0.108664+0.00297115\ttest-rmse:0.12396+0.0119963\n",
      "[880]\ttrain-rmse:0.108442+0.00294592\ttest-rmse:0.123923+0.0120049\n",
      "[890]\ttrain-rmse:0.108248+0.00292734\ttest-rmse:0.123802+0.0119628\n",
      "[900]\ttrain-rmse:0.108069+0.00291352\ttest-rmse:0.123763+0.0119544\n",
      "[910]\ttrain-rmse:0.107873+0.00290088\ttest-rmse:0.123682+0.0119493\n",
      "[920]\ttrain-rmse:0.107695+0.00289097\ttest-rmse:0.123597+0.0119049\n",
      "[930]\ttrain-rmse:0.107521+0.00288207\ttest-rmse:0.123491+0.0119224\n",
      "[940]\ttrain-rmse:0.107364+0.00286643\ttest-rmse:0.123458+0.0119602\n",
      "[950]\ttrain-rmse:0.107205+0.00286939\ttest-rmse:0.123429+0.0119796\n",
      "[960]\ttrain-rmse:0.107054+0.00285371\ttest-rmse:0.123368+0.01198\n",
      "[970]\ttrain-rmse:0.106899+0.00285191\ttest-rmse:0.123363+0.0119316\n",
      "[980]\ttrain-rmse:0.106754+0.00284277\ttest-rmse:0.123324+0.011918\n",
      "[990]\ttrain-rmse:0.106607+0.00284527\ttest-rmse:0.123286+0.0119262\n",
      "Ensemble-CV: 0.12330425+0.0119459587806\n"
     ]
    }
   ],
   "source": [
    "# Stacking Starter based on Allstate Faron's Script\n",
    "#https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter/run/390867\n",
    "# Preprocessing from Alexandru Papiu\n",
    "#https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, Lasso\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "TARGET = 'SalePrice'\n",
    "NFOLDS = 5\n",
    "SEED = 0\n",
    "NROWS = None\n",
    "SUBMISSION_FILE = 'input/sample_submission.csv'\n",
    "\n",
    "\n",
    "## Load the data ##\n",
    "train = pd.read_csv(\"input/train.csv\")\n",
    "test = pd.read_csv(\"input/test.csv\")\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "## Preprocessing ##\n",
    "\n",
    "y_train = np.log(train[TARGET]+1)\n",
    "\n",
    "\n",
    "train.drop([TARGET], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']))\n",
    "\n",
    "\n",
    "#log transform skewed numeric features:\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
    "\n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "#filling NA's with the mean of the column:\n",
    "all_data = all_data.fillna(all_data.mean())\n",
    "\n",
    "#creating matrices for sklearn:\n",
    "\n",
    "x_train = np.array(all_data[:train.shape[0]])\n",
    "x_test = np.array(all_data[train.shape[0]:])\n",
    "\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "\n",
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "et_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'rmse',\n",
    "    'nrounds': 500\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "rd_params={\n",
    "    'alpha': 10\n",
    "}\n",
    "\n",
    "\n",
    "ls_params={\n",
    "    'alpha': 0.005\n",
    "}\n",
    "\n",
    "\n",
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "rd = SklearnWrapper(clf=Ridge, seed=SEED, params=rd_params)\n",
    "ls = SklearnWrapper(clf=Lasso, seed=SEED, params=ls_params)\n",
    "\n",
    "xg_oof_train, xg_oof_test = get_oof(xg)\n",
    "et_oof_train, et_oof_test = get_oof(et)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf)\n",
    "rd_oof_train, rd_oof_test = get_oof(rd)\n",
    "ls_oof_train, ls_oof_test = get_oof(ls)\n",
    "\n",
    "print(\"XG-CV: {}\".format(sqrt(mean_squared_error(y_train, xg_oof_train))))\n",
    "print(\"ET-CV: {}\".format(sqrt(mean_squared_error(y_train, et_oof_train))))\n",
    "print(\"RF-CV: {}\".format(sqrt(mean_squared_error(y_train, rf_oof_train))))\n",
    "print(\"RD-CV: {}\".format(sqrt(mean_squared_error(y_train, rd_oof_train))))\n",
    "print(\"LS-CV: {}\".format(sqrt(mean_squared_error(y_train, ls_oof_train))))\n",
    "\n",
    "\n",
    "x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train, rd_oof_train, ls_oof_train), axis=1)\n",
    "x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test, rd_oof_test, ls_oof_test), axis=1)\n",
    "\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 1,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'rmse',\n",
    "}\n",
    "\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=1000, nfold=4, seed=SEED, stratified=False,\n",
    "             early_stopping_rounds=25, verbose_eval=10, show_stdv=True)\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "\n",
    "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
    "\n",
    "gbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "#creating matrices for sklearn:\n",
    "X_train = all_data[:train.shape[0]]\n",
    "X_test = all_data[train.shape[0]:]\n",
    "\n",
    "model_lasso = LassoCV()\n",
    "alphas = [1, 0.1, 0.001, 0.0005]\n",
    "model_lasso = LassoCV(alphas = alphas).fit(X_train, y_train)\n",
    "lasso_preds = np.expm1(model_lasso.predict(X_test))\n",
    "\n",
    "submission = pd.read_csv(SUBMISSION_FILE)\n",
    "submission.iloc[:, 1] = gbdt.predict(dtest)\n",
    "saleprice = np.exp(submission['SalePrice'])-1\n",
    "\n",
    "\n",
    "preds = 0.5*lasso_preds + 0.5*saleprice\n",
    "\n",
    "\n",
    "submission['SalePrice'] = preds\n",
    "submission.to_csv('xgstackerweightedhalf.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
